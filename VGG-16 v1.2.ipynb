{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this function standardizes the dimensions of the image as per the given dimensions and returns a vectorized form of the image(num_x*num_y*3,1)\n",
    "# input: full path of the image, required X dimension of the image, required Y dimension of the image\n",
    "# returns: vectorized image - dimensions [num_x*num*y*3,1] \n",
    "def standardize_image(path,num_x,num_y):\n",
    "    image = np.array(ndimage.imread(path, flatten=False))\n",
    "#     channel_image = np.zeros((3,num_x,num_y))\n",
    "\n",
    "    #print(\"original image\"+str(image.shape))\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "    stdsize_image = scipy.misc.imresize(image,size=(num_x,num_y))  ## image in form x,y,3\n",
    "#     channel_image[0,...] = stdsize_image[...,0]\n",
    "#     channel_image[1,...] = stdsize_image[...,1]\n",
    "#     channel_image[2,...] = stdsize_image[...,2]\n",
    "#     channel_image = channel_image.astype(int)\n",
    "#     my_image = stdsize_image.reshape((1, num_x*num_y*3)).T\n",
    "    return stdsize_image      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples:765\n",
      "(765, 64, 64, 3)\n",
      "(765, 1)\n",
      "325.0\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################################################\n",
    "#################################### Standardize and Vectorize the training data set ############################################\n",
    "import os\n",
    "import re\n",
    "num_x = 64\n",
    "num_y = 64\n",
    "\n",
    "imagelist = os.listdir(\"D:/ISEEC/Analytics resources/Image Recognition/Images/throughurls/mixed/incAugImages\")\n",
    "path=\"D:/ISEEC/Analytics resources/Image Recognition/Images/throughurls/mixed/incAugImages\"\n",
    "print(\"No. of samples:\"+str(len(imagelist)))\n",
    "random.shuffle(imagelist)\n",
    "m = len(imagelist)\n",
    "X = np.zeros((m,num_x,num_y,3))\n",
    "Y = np.zeros((m,1))\n",
    "count = 0\n",
    "for i in imagelist:\n",
    "#     print(imagevector.shape)\n",
    "#         imagevector = standardize_image(path+\"/\"+i,num_x,num_y) \n",
    "#         image = np.array(ndimage.imread(path+\"/\"+i, flatten=False))\n",
    "    #print(\"original image\"+str(image.shape))\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "#         stdsize_image = scipy.misc.imresize(image,size=(num_x,num_y))\n",
    "#         X[count,...] = stdsize_image\n",
    "        imagevector = standardize_image(path+\"/\"+i,num_x,num_y)\n",
    "#         print(imagevector.shape)\n",
    "        try:\n",
    "            X[count,...] = imagevector\n",
    "        except:\n",
    "            X[count,...] = np.resize(imagevector, (num_x, num_y, 3))\n",
    "        if re.search(\"neg\",i):\n",
    "            Y[count,0] = 0\n",
    "        else:\n",
    "            Y[count,0] = 1\n",
    "#         print(i)\n",
    "#         print(imagevector.shape)    \n",
    "#         print(i+str(Y[0,count]))\n",
    "        count += 1    \n",
    "# X = X/255\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "# print(\"X is: \"+str(X))\n",
    "# print(\"Y is: \"+str(Y))\n",
    "print(np.sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " succesfully made network\n",
      "[<tf.Variable 'conv2d_57/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'conv2d_57/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2d_58/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'conv2d_58/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2d_59/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv2d_59/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv2d_60/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'conv2d_60/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'dense_43/kernel:0' shape=(32768, 800) dtype=float32_ref>, <tf.Variable 'dense_43/bias:0' shape=(800,) dtype=float32_ref>, <tf.Variable 'dense_44/kernel:0' shape=(800, 800) dtype=float32_ref>, <tf.Variable 'dense_44/bias:0' shape=(800,) dtype=float32_ref>, <tf.Variable 'dense_45/kernel:0' shape=(800, 1) dtype=float32_ref>, <tf.Variable 'dense_45/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "## build architecture\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "################################################### conv layers #########################################################\n",
    "\n",
    "## conv layer\n",
    "model.add(keras.layers.Conv2D(64, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', input_shape=(num_x,num_y,3),use_bias=True, bias_initializer='zeros'))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "## max pool layer\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=None, padding='valid',data_format=None))\n",
    "\n",
    "## conv layer\n",
    "model.add(keras.layers.Conv2D(128, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', input_shape=(num_x,num_y,3),use_bias=True, bias_initializer='zeros'))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "## max pool layer\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=None, padding='valid',data_format=None))\n",
    "\n",
    "# ## conv layer\n",
    "# model.add(keras.layers.Conv2D(256, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', input_shape=(num_x,num_y,3),use_bias=True, bias_initializer='zeros'))\n",
    "# model.add(keras.layers.Conv2D(256, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "# model.add(keras.layers.Conv2D(256, (1,1), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "# ## max pool layer\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=None, padding='valid',data_format=None))\n",
    "\n",
    "# ## conv layer\n",
    "# model.add(keras.layers.Conv2D(512, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', input_shape=(num_x,num_y,3),use_bias=True, bias_initializer='zeros'))\n",
    "# model.add(keras.layers.Conv2D(512, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "# model.add(keras.layers.Conv2D(512, (1,1), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "# ## max pool layer\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=None, padding='valid',data_format=None))\n",
    "\n",
    "# ## conv layer\n",
    "# model.add(keras.layers.Conv2D(512, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', input_shape=(num_x,num_y,3),use_bias=True, bias_initializer='zeros'))\n",
    "# model.add(keras.layers.Conv2D(512, (3,3), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "# model.add(keras.layers.Conv2D(512, (1,1), strides=(1, 1), padding='same',kernel_initializer = 'random_uniform', activation='relu', use_bias=True, bias_initializer='zeros'))\n",
    "# ## max pool layer\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=None, padding='valid',data_format=None))\n",
    "\n",
    "\n",
    "#################################### Flatten   #####################################################\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "#################################### FC layers !!!   #####################################################\n",
    "model.add(Dense(units=800, activation='relu',kernel_initializer = 'random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(units=800, activation='relu',kernel_initializer = 'random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(units=1, activation='sigmoid',kernel_initializer = 'random_uniform',bias_initializer='zeros'))\n",
    "# sgd = keras.optimizers.sgd(lr=0.5)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\" succesfully made network\")\n",
    "print(model.weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(765, 64, 64, 3)\n",
      "(9, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X[1:10,...].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(765, 64, 64, 3)\n",
      "(765, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-5b1773f737d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m765\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m765\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnan_close\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "## Run model\n",
    "csv_logger = keras.callbacks.CSVLogger('D:\\ISEEC\\Analytics resources\\KerasLogs\\kerasvgg16v1.0.log',append=False)\n",
    "nan_close = keras.callbacks.TerminateOnNaN()\n",
    "# tboard = keras.callbacks.TensorBoard(log_dir='D:\\ISEEC\\Analytics resources\\KerasLogs', histogram_freq=0, batch_size=50, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "model.fit(X[0:765,...]/255, Y[0:765,...], batch_size=32, epochs=25,callbacks=[csv_logger,nan_close],verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765/765 [==============================] - 32s 42ms/step\n",
      "[2.605161631804757e-05, 1.0]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X/255, Y, batch_size=32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Save model\n",
    "modeljson = model.to_json()\n",
    "with open(\"D:\\ISEEC\\Analytics resources\\KerasLogs\\Basemodel.json\", \"w\") as json_file:\n",
    "    json_file.write(modeljson)\n",
    "    \n",
    "### save weights    \n",
    "model.save_weights(\"D:\\ISEEC\\Analytics resources\\KerasLogs\\Basemodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples:236\n",
      "(236, 64, 64, 3)\n",
      "(236, 1)\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "## load test set\n",
    "\n",
    "imagelist = os.listdir(\"D:/ISEEC/Analytics resources/Image Recognition/Images/throughurls/mixed/test\")\n",
    "path=\"D:/ISEEC/Analytics resources/Image Recognition/Images/throughurls/mixed/test\"\n",
    "print(\"No. of samples:\"+str(len(imagelist)))\n",
    "random.shuffle(imagelist)\n",
    "m = len(imagelist)\n",
    "X_test = np.zeros((m,num_x,num_y,3))\n",
    "Y_test = np.zeros((m,1))\n",
    "count = 0\n",
    "for i in imagelist:\n",
    "#     print(imagevector.shape)\n",
    "#         imagevector = standardize_image(path+\"/\"+i,num_x,num_y) \n",
    "#         image = np.array(ndimage.imread(path+\"/\"+i, flatten=False))\n",
    "    #print(\"original image\"+str(image.shape))\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "#         stdsize_image = scipy.misc.imresize(image,size=(num_x,num_y))\n",
    "#         X[count,...] = stdsize_image\n",
    "        imagevector = standardize_image(path+\"/\"+i,num_x,num_y)\n",
    "#         print(imagevector.shape)\n",
    "        try:\n",
    "            X_test[count,...] = imagevector\n",
    "        except:\n",
    "            X_test[count,...] = np.resize(imagevector, (num_x, num_y, 3))\n",
    "        if re.search(\"neg\",i):\n",
    "            Y_test[count,0] = 0\n",
    "        else:\n",
    "            Y_test[count,0] = 1\n",
    "#         print(i)\n",
    "#         print(imagevector.shape)    \n",
    "#         print(i+str(Y[0,count]))\n",
    "        count += 1    \n",
    "# X = X/255\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "# print(\"X is: \"+str(X))\n",
    "# print(\"Y is: \"+str(Y))\n",
    "print(np.sum(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 10s 43ms/step\n",
      "[2.2440551216319458, 0.74576271186440679]\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights(\"D:\\ISEEC\\Analytics resources\\KerasLogs\\model.h5\")\n",
    "\n",
    "score = model.evaluate(X_test/255, Y_test, batch_size=32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208.0\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-8099d652e512>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'D:\\ISEEC\\Analytics resources\\KerasLogs\\model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "print(np.sum(Y[2500:3000,...]))\n",
    "import pydot\n",
    "import graphviz\n",
    "keras.utils.plot_model(model, to_file='D:\\ISEEC\\Analytics resources\\KerasLogs\\model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save model\n",
    "modeljson = model.to_json()\n",
    "with open(\"D:\\ISEEC\\Analytics resources\\KerasLogs\\Basemodel.json\", \"w\") as json_file:\n",
    "    json_file.write(modeljson)\n",
    "    \n",
    "### save weights    \n",
    "model.save_weights(\"D:\\ISEEC\\Analytics resources\\KerasLogs\\Basemodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Flatten object at 0x0000000058C68E80>\n",
      "[{'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'batch_input_shape': (None, 64, 64, 3), 'dtype': 'float32', 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'batch_input_shape': (None, 64, 64, 3), 'dtype': 'float32', 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'units': 800, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_20', 'trainable': True, 'units': 800, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 64, 64, 3), dtype=float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.get_layer(index=7))\n",
    "print(model.get_config())\n",
    "X = X/255\n",
    "X[0:0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## script for downloading images in local from image URLs\n",
    "import urllib.request as req\n",
    "imgurl =\"http://www.vision.caltech.edu/Image_Datasets/Caltech256/images/126.ladder/126_0\"\n",
    "jpg = \".jpg\"\n",
    "count = 315\n",
    "for i in range(1,243):\n",
    "    imageNo = \"00\" + str(i)\n",
    "    imageNo = imageNo[-3:]\n",
    "    path = imgurl + imageNo + jpg\n",
    "    req.urlretrieve(path, \"D:/ISEEC/Analytics resources/Image Recognition/Images/throughurls/caltech/image\"+str(count)+\".jpg\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 576 image(s) found.\n",
      "Output directory set to D:/ISEEC/Analytics resources/Image Recognition/Images/throughurls/mixed/non ladder\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "### Image data augmentation   used Flip_left_right and skew on each image\n",
    "import Augmentor\n",
    "p = Augmentor.Pipeline(\"D:/ISEEC/Analytics resources/Image Recognition/Images/throughurls/mixed/non ladder\")\n",
    "p.flip_left_right(probability=1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "# p.skew(probability=1)\n",
    "p.sample(576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"D:/ISEEC/Analytics resources/Image Recognition/Images/throughurls/mixed/non ladder/output\"\n",
    "imagenames = os.listdir(path)\n",
    "no_of_images = len(imagenames)\n",
    "count = 673\n",
    "for i in imagenames:\n",
    "    os.rename(path+str(\"/\")+i,path+str(\"/\")+\"negimageAug\"+str(count)+\".jpg\")\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?os.rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
